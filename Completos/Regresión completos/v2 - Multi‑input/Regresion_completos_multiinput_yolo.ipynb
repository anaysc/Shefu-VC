{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6deb724a",
   "metadata": {},
   "source": [
    "# Shefu — YOLOv8 + Regresión Multi‑Entrada (Imagen + Binarios)\n",
    "\n",
    "Este cuaderno **integra** el detector **YOLOv8** (para recortar el completo) con un **regresor multi‑entrada** (imagen recortada + 4 banderas de `motivo`) para producir una **nota 0–100**.\n",
    "\n",
    "## Resumen del flujo\n",
    "1. **Detector (YOLOv8)**: foto completa → **ROI** del completo.\n",
    "2. **Pre‑procesamiento**: recorte, resize, normalización.\n",
    "3. **Multi‑input**: embeddings visuales + 4 flags.\n",
    "4. **Regresión**: nota 0–100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b36785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional) Instalar deps si tu entorno no las tiene.\n",
    "# !pip install ultralytics==8.2.103 tensorflow==2.15.0 pandas==2.1.4 numpy==1.26.4 scikit-learn==1.3.2 matplotlib==3.8.0\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os, json, ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('TensorFlow:', tf.__version__)\n",
    "print('GPU devices:', tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Configuración\n",
    "# =====================\n",
    "DATA_CSV_PATH = '/mnt/data/project-2-at-2025-09-12-06-46-b36c7e7f.csv'  # <- AJUSTA\n",
    "IMAGES_ROOT  = '/mnt/data/images'                                        # <- AJUSTA\n",
    "YOLO_WEIGHTS = '/mnt/data/completos_detector.pt'                         # <- AJUSTA\n",
    "CROPS_DIR    = '/mnt/data/crops_yolo'\n",
    "\n",
    "IMG_SIZE     = 224\n",
    "BATCH_SIZE   = 16\n",
    "EPOCHS       = 25\n",
    "VAL_SPLIT    = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "os.makedirs(CROPS_DIR, exist_ok=True)\n",
    "print('CSV:', DATA_CSV_PATH)\n",
    "print('IMAGES_ROOT:', IMAGES_ROOT)\n",
    "print('YOLO_WEIGHTS:', YOLO_WEIGHTS)\n",
    "print('CROPS_DIR:', CROPS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6da7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Parsing score y motivo\n",
    "# =====================\n",
    "def parse_score_field(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    try:\n",
    "        data = json.loads(x)\n",
    "        if isinstance(data, list) and len(data) > 0 and 'number' in data[0]:\n",
    "            return float(data[0]['number'])\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        data = ast.literal_eval(x)\n",
    "        if isinstance(data, list) and len(data) > 0 and 'number' in data[0]:\n",
    "            return float(data[0]['number'])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return np.nan\n",
    "\n",
    "def parse_motivo_to_flags(motivo):\n",
    "    flags = {'pan_quemado':0, 'falta_ingrediente':0, 'desordenado':0, 'buen_balance_visual':0}\n",
    "    if pd.isna(motivo):\n",
    "        return flags\n",
    "    text = str(motivo)\n",
    "    choices = None\n",
    "    if '\"choices\"' in text or \"'choices'\" in text:\n",
    "        try:\n",
    "            obj = json.loads(text)\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = ast.literal_eval(text)\n",
    "            except Exception:\n",
    "                obj = None\n",
    "        if isinstance(obj, dict) and 'choices' in obj:\n",
    "            choices = obj['choices']\n",
    "\n",
    "    def set_from_string(s):\n",
    "        s = s.lower()\n",
    "        if 'pan quemado' in s:\n",
    "            flags['pan_quemado']=1\n",
    "        if 'falta de ingrediente' in s:\n",
    "            flags['falta_ingrediente']=1\n",
    "        if 'desordenado' in s:\n",
    "            flags['desordenado']=1\n",
    "        if 'buen balance visual' in s:\n",
    "            flags['buen_balance_visual']=1\n",
    "\n",
    "    if choices is None:\n",
    "        set_from_string(text)\n",
    "    else:\n",
    "        for c in choices:\n",
    "            set_from_string(str(c))\n",
    "    return flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# YOLOv8 → crop con cache\n",
    "# =====================\n",
    "detector = YOLO(YOLO_WEIGHTS)\n",
    "\n",
    "def yolo_crop_to_file(img_path, save_dir=CROPS_DIR, conf=0.25):\n",
    "    base = os.path.basename(img_path)\n",
    "    crop_path = os.path.join(save_dir, base)\n",
    "    if os.path.exists(crop_path):\n",
    "        return crop_path\n",
    "    results = detector(img_path, conf=conf, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int) if len(results)>0 else np.array([])\n",
    "    if boxes.shape[0]==0:\n",
    "        return None\n",
    "    x1,y1,x2,y2 = boxes[0]\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    h,w = img.shape[:2]\n",
    "    x1,y1 = max(0,x1), max(0,y1)\n",
    "    x2,y2 = min(w,x2), min(h,y2)\n",
    "    crop = img[y1:y2, x1:x2]\n",
    "    if crop.size==0:\n",
    "        return None\n",
    "    cv2.imwrite(crop_path, crop)\n",
    "    return crop_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Construcción del dataframe con crops\n",
    "# =====================\n",
    "df = pd.read_csv(DATA_CSV_PATH)\n",
    "df['score_clean'] = df['score'].apply(parse_score_field)\n",
    "flags = df['motivo'].apply(parse_motivo_to_flags)\n",
    "for k in ['pan_quemado','falta_ingrediente','desordenado','buen_balance_visual']:\n",
    "    df[k] = flags.apply(lambda d: d[k])\n",
    "\n",
    "def resolve_original_path(p):\n",
    "    if pd.isna(p):\n",
    "        return None\n",
    "    base = os.path.basename(str(p))\n",
    "    return os.path.join(IMAGES_ROOT, base)\n",
    "\n",
    "df['orig_path'] = df['data'].apply(resolve_original_path)\n",
    "\n",
    "crop_paths = []\n",
    "missing = 0\n",
    "for p in df['orig_path'].tolist():\n",
    "    if p is None or not os.path.exists(p):\n",
    "        crop_paths.append(None)\n",
    "        missing += 1\n",
    "        continue\n",
    "    cp = yolo_crop_to_file(p, save_dir=CROPS_DIR, conf=0.25)\n",
    "    crop_paths.append(cp)\n",
    "\n",
    "df['crop_path'] = crop_paths\n",
    "df = df.dropna(subset=['score_clean','crop_path']).reset_index(drop=True)\n",
    "df = df[df['crop_path'].apply(lambda p: os.path.exists(p))].reset_index(drop=True)\n",
    "\n",
    "print('Total con crop válido:', len(df))\n",
    "if missing>0:\n",
    "    print(f'Advertencia: {missing} imágenes originales no se encontraron en IMAGES_ROOT.')\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247bcb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# tf.data (crops + flags)\n",
    "# =====================\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=VAL_SPLIT, random_state=RANDOM_STATE, shuffle=True\n",
    ")\n",
    "\n",
    "def load_and_resize(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = tf.cast(img, tf.float32)/255.0\n",
    "    return img\n",
    "\n",
    "def augment(img):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.1)\n",
    "    img = tf.image.random_contrast(img, 0.9, 1.1)\n",
    "    return img\n",
    "\n",
    "BIN_COLS = ['pan_quemado','falta_ingrediente','desordenado','buen_balance_visual']\n",
    "\n",
    "def make_ds(frame, bs, training=True):\n",
    "    img_paths = frame['crop_path'].values\n",
    "    y = (frame['score_clean'].values/100.0).astype(np.float32)\n",
    "    xbin = frame[BIN_COLS].values.astype(np.float32)\n",
    "    ds_img = tf.data.Dataset.from_tensor_slices(img_paths).map(load_and_resize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if training:\n",
    "        ds_img = ds_img.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_bin = tf.data.Dataset.from_tensor_slices(xbin)\n",
    "    ds_y   = tf.data.Dataset.from_tensor_slices(y)\n",
    "    ds = tf.data.Dataset.zip(((ds_img, ds_bin), ds_y))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(frame), reshuffle_each_iteration=True)\n",
    "    return ds.batch(bs).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_ds(train_df, BATCH_SIZE, training=True)\n",
    "val_ds   = make_ds(val_df,   BATCH_SIZE, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13fa1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Modelo multi‑entrada\n",
    "# =====================\n",
    "inp_img = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='img')\n",
    "backbone = MobileNetV3Small(include_top=False, weights='imagenet', input_tensor=inp_img)\n",
    "backbone.trainable = False\n",
    "x1 = layers.GlobalAveragePooling2D()(backbone.output)\n",
    "x1 = layers.Dense(128, activation='relu')(x1)\n",
    "\n",
    "inp_bin = layers.Input(shape=(4,), name='bin')\n",
    "x2 = layers.Dense(16, activation='relu')(inp_bin)\n",
    "\n",
    "x  = layers.Concatenate()([x1, x2])\n",
    "x  = layers.Dense(64, activation='relu')(x)\n",
    "x  = layers.Dropout(0.3)(x)\n",
    "out = layers.Dense(1, activation='linear', name='score')(x)\n",
    "\n",
    "model = models.Model(inputs=[inp_img, inp_bin], outputs=out)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e553d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Entrenamiento Fase 1\n",
    "# =====================\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "history1 = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n",
    "\n",
    "plt.figure(); plt.plot(history1.history['loss'], label='train'); plt.plot(history1.history['val_loss'], label='val'); plt.title('MSE'); plt.legend(); plt.show()\n",
    "plt.figure(); plt.plot(history1.history['mae'], label='train'); plt.plot(history1.history['val_mae'], label='val'); plt.title('MAE'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Fine‑tuning\n",
    "# =====================\n",
    "N = 20\n",
    "for layer in backbone.layers[-N:]:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='mse', metrics=['mae'])\n",
    "history2 = model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks)\n",
    "\n",
    "plt.figure(); plt.plot(history2.history['loss'], label='train_ft'); plt.plot(history2.history['val_loss'], label='val_ft'); plt.title('MSE Fine‑tuning'); plt.legend(); plt.show()\n",
    "plt.figure(); plt.plot(history2.history['mae'], label='train_ft'); plt.plot(history2.history['val_mae'], label='val_ft'); plt.title('MAE Fine‑tuning'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01713c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Guardar modelo y TFLite\n",
    "# =====================\n",
    "OUTPUT_DIR = '/mnt/data'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "keras_path  = os.path.join(OUTPUT_DIR, 'shefu_multiinput_yolo.h5')\n",
    "tflite_path = os.path.join(OUTPUT_DIR, 'shefu_multiinput_yolo.tflite')\n",
    "model.save(keras_path)\n",
    "print('Guardado Keras:', keras_path)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print('Guardado TFLite:', tflite_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Inferencia end‑to‑end (YOLO + crop + regresor)\n",
    "# =====================\n",
    "def infer_full_image(image_path, flags_vec, conf=0.25):\n",
    "    cp = yolo_crop_to_file(image_path, save_dir=CROPS_DIR, conf=conf)\n",
    "    if cp is None or not os.path.exists(cp):\n",
    "        print('No se pudo obtener crop del completo.')\n",
    "        return None\n",
    "    img = tf.image.decode_jpeg(tf.io.read_file(cp), channels=3)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = tf.cast(img, tf.float32)/255.0\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    xbin = np.array(flags_vec, dtype=np.float32).reshape(1, -1)\n",
    "    pred = model.predict([img, xbin], verbose=0)[0,0]\n",
    "    score = float(np.clip(pred, 0, 1)*100.0)\n",
    "    print(f'Nota estimada: {score:.1f}/100  (flags={flags_vec})')\n",
    "    return score\n",
    "\n",
    "# Ejemplo:\n",
    "# infer_full_image('/mnt/data/images/ejemplo.jpg', [0,0,1,0])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
